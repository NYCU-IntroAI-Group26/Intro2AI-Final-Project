{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download the necessary resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# set up the necessary resources\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def clean_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the spelling\n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "# remove the stop words and stem the words\n",
    "def preprocess_text(text):\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning the text: 100%|██████████| 129670/129670 [00:01<00:00, 90956.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing the text: 100%|██████████| 129670/129670 [00:14<00:00, 9038.96it/s] \n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('../dataset/process/en-2020-01-merged-cleaned-without-emoji.tsv', sep='\\t')\n",
    "\n",
    "data['text'] = data['text'].astype(str)\n",
    "\n",
    "print('Cleaning the text...')\n",
    "tqdm.pandas(desc=\"Cleaning the text\")\n",
    "data['text'] = data['text'].progress_apply(clean_punctuation)\n",
    "\n",
    "# print('Correcting the spelling...')\n",
    "# tqdm.pandas(desc=\"Correcting the spelling\")\n",
    "# data['text'] = data['text'].progress_apply(correct_spelling)\n",
    "\n",
    "print('Preprocessing the text...')\n",
    "tqdm.pandas(desc=\"Preprocessing the text\")\n",
    "data['text'] = data['text'].progress_apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "data.to_csv('../dataset/process/en-2020-01-merged-cleaned-without-emoji-tfidf.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the vectorizer...\n",
      "Transforming the text...\n",
      "  (0, 895)\t0.39324661930528254\n",
      "  (0, 3437)\t0.28855800864442493\n",
      "  (0, 3699)\t0.27147908555651307\n",
      "  (0, 4994)\t0.3154779615420935\n",
      "  (0, 5899)\t0.27224176192334815\n",
      "  (0, 7934)\t0.3899710457588365\n",
      "  (0, 8677)\t0.41145225670211\n",
      "  (0, 9769)\t0.3529729164331398\n",
      "  (0, 9810)\t0.2622752393818948\n",
      "  (1, 3699)\t0.2964903619249672\n",
      "  (1, 5698)\t0.6739142048964195\n",
      "  (1, 5899)\t0.2973233034076269\n",
      "  (1, 8738)\t0.35210313961603085\n",
      "  (1, 9130)\t0.40436158140381434\n",
      "  (1, 9810)\t0.28643856851399285\n",
      "  (2, 2128)\t0.8304695197580235\n",
      "  (2, 3699)\t0.3249432459255961\n",
      "  (2, 5899)\t0.3258561211613517\n",
      "  (2, 9810)\t0.3139268258398662\n",
      "  (3, 5038)\t0.38797867140990316\n",
      "  (3, 5724)\t0.4796125374965737\n",
      "  (3, 9894)\t0.7870478793612902\n",
      "  (4, 305)\t0.734544170740822\n",
      "  (4, 5937)\t0.6785608751104636\n",
      "  (5, 450)\t0.5357856068527261\n",
      "  :\t:\n",
      "  (129662, 9268)\t0.3397720138639089\n",
      "  (129662, 9673)\t0.21179485404751677\n",
      "  (129663, 8088)\t1.0\n",
      "  (129664, 5298)\t0.6429656458583077\n",
      "  (129664, 6686)\t0.7658950177707184\n",
      "  (129665, 5073)\t0.7175237833529847\n",
      "  (129665, 9001)\t0.6965340051446295\n",
      "  (129666, 2618)\t0.33504824196257216\n",
      "  (129666, 3404)\t0.3089313869177626\n",
      "  (129666, 3598)\t0.34907605832318894\n",
      "  (129666, 3699)\t0.21840580721030695\n",
      "  (129666, 3741)\t0.3577920051807689\n",
      "  (129666, 7095)\t0.3396019257504692\n",
      "  (129666, 8150)\t0.4896102878505917\n",
      "  (129666, 8214)\t0.2784198204856792\n",
      "  (129666, 9374)\t0.24933604886597852\n",
      "  (129667, 8548)\t1.0\n",
      "  (129668, 824)\t0.5457170636431407\n",
      "  (129668, 3826)\t0.5620239179077101\n",
      "  (129668, 8250)\t0.4937191676153577\n",
      "  (129668, 9810)\t0.3775756688103381\n",
      "  (129669, 885)\t0.40410059431812184\n",
      "  (129669, 2900)\t0.4877028714324166\n",
      "  (129669, 3699)\t0.30028177134369444\n",
      "  (129669, 7065)\t0.7132176923401506\n"
     ]
    }
   ],
   "source": [
    "# initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# fit the vectorizer\n",
    "print('Fitting the vectorizer...')\n",
    "vectorizer.fit(data['text'])\n",
    "\n",
    "# transform the text\n",
    "print('Transforming the text...')\n",
    "X = vectorizer.transform(data['text'])\n",
    "\n",
    "# save the data\n",
    "scipy.sparse.save_npz('../dataset/process/tfidf_sparse.npz', X)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
