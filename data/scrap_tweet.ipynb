{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Archive\n",
    "Twitter Stream Grab archive (https://archive.org/details/twitterstream)\n",
    "\n",
    "> A simple collection of JSON grabbed from the general twitter stream, for the purposes of research, history, testing and memory. \n",
    "\n",
    "Download orgin tweet content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡ä»¶å¤¾è·¯å¾‘\n",
    "folder_path = '../dataset/twitter_stream_2020_01_02/02/'\n",
    "\n",
    "# åˆå§‹åŒ–åˆ—è¡¨ä¾†å­˜å„²æ¨æ–‡çš„æ–‡æœ¬å’ŒID\n",
    "tweets_data = []\n",
    "\n",
    "# éæ­·æ–‡ä»¶å¤¾ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    print(f'Processing {root} folder...')\n",
    "    for file in files:\n",
    "        if file.endswith('.bz2'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with bz2.open(file_path, 'rt') as bz_file:\n",
    "                for line in bz_file:\n",
    "                    tweet = json.loads(line)\n",
    "                    # print(tweet)\n",
    "                    tweet_id = tweet.get('id_str')\n",
    "                    tweet_text = tweet.get('text')\n",
    "                    if tweet_id and tweet_text:\n",
    "                        tweets_data.append({'id': tweet_id, 'text': tweet_text})\n",
    "\n",
    "# å‰µå»ºDataFrame\n",
    "tweets_df = pd.DataFrame(tweets_data)\n",
    "\n",
    "# ä¿å­˜ç‚ºCSVæ–‡ä»¶\n",
    "tweets_df.to_csv('tweets_data_2020_01_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                               text\n",
      "0  1212636897220030464                     å±äººè˜è¦‹ã‚ˆã†ã‹ã‚¹ã‚¿ãƒ¼ã‚¦ã‚©ãƒ¼ã‚ºè¦‹ã‚ˆã†ã‹å¯…ã•ã‚“è¦‹ã‚ˆã†ã‹è¿·ã£ã¦ã‚‹ã€‚\n",
      "1  1212636897236766721  RT @NBBAM: à¸•à¸­à¸™à¸™à¹‰à¸­à¸‡à¸¥à¸´à¸‹à¹€à¸›à¹‡à¸™à¸¥à¸´à¸‹à¹ˆà¸²à¹à¸šà¸¥à¹‡à¸„à¸à¸´à¸‡à¸„à¹Œ à¸‰à¸²à¸¢à¸²à¸—...\n",
      "2  1212636897220030466  RT @kae95593567: à¸£à¸±à¸šà¸ªà¸¡à¸±à¸„à¸„à¸™à¸‹à¹‰à¸­à¸™à¸—à¹‰à¸²à¸¢à¸«à¸™à¸¶à¹ˆà¸‡à¸­à¸±à¸•à¸£à¸²à¸„à¹ˆ...\n",
      "3  1212636897224183808  RT @info_tomonokai: ğŸ†™ã€ç¬¬ï¼™ï¼•å¼¾ã€‘ã€ç™¾è²¨åº—å‹ã®ä¼šã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã€å…¬å¼ã‚¢ã‚«ã‚¦...\n",
      "4  1212636897236803585         @colomao0818 ã»ã‚“ã¨ç¹‹ã’æ–¹ãŒæ€ã„ã¤ã‹ãªã„ã‘ã©ã„ã–çµ‚ã‚ã‚‹ã£ã¦è€ƒãˆã‚‹ã¨ã¤ã‚‰ã„\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3722541, 2)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
